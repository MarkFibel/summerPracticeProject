{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers datasets torchvision matplotlib accelerate evaluate jiwer sacrebleu rouge-score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import load_dataset\nimport torch\n\ntrain_dataset = load_dataset(\"linxy/LaTeX_OCR\", name=\"full\", split=\"train\")\nval_dataset = load_dataset(\"linxy/LaTeX_OCR\", name=\"full\", split=\"validation\")\n\nprint(f\"Train size: {len(train_dataset)}\")\nprint(f\"Val size: {len(val_dataset)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n\nmodel = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-stage1\")\nprocessor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-stage1\")\n\nmodel.config.decoder_start_token_id = processor.tokenizer.cls_token_id\nmodel.config.pad_token_id = processor.tokenizer.pad_token_id\nmodel.config.vocab_size = model.config.decoder.vocab_size","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def preprocess(example):\n    image = example[\"image\"].convert(\"RGB\")\n    pixel_values = processor(images=image, return_tensors=\"pt\").pixel_values[0]\n    input_ids = processor.tokenizer(\n        example[\"text\"],\n        padding=\"max_length\",\n        max_length=256,\n        truncation=True,\n        return_tensors=\"pt\"\n    ).input_ids[0]\n    example[\"pixel_values\"] = pixel_values\n    example[\"labels\"] = input_ids\n    return example\n\ntrain_dataset = train_dataset.map(preprocess)\nval_dataset = val_dataset.map(preprocess)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import Dataset\n\nclass LaTeXDataset(Dataset):\n    def __init__(self, hf_dataset):\n        self.dataset = hf_dataset\n\n    def __len__(self):\n        return len(self.dataset)\n\n    def __getitem__(self, idx):\n        item = self.dataset[idx]\n        return {\n            \"pixel_values\": item[\"pixel_values\"],\n            \"labels\": item[\"labels\"],\n        }\n\ntrain_torch_ds = LaTeXDataset(train_dataset)\nval_torch_ds = LaTeXDataset(val_dataset)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"./trocr_latex\",\n    eval_strategy=\"epoch\",\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    predict_with_generate=True,\n    logging_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    num_train_epochs=100,\n    save_total_limit=1,\n    logging_dir=\"./logs\",\n    report_to=\"none\",\n    fp16=torch.cuda.is_available(),\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import evaluate\n\ncer_metric = evaluate.load(\"cer\")\nwer_metric = evaluate.load(\"wer\")\n\ndef compute_metrics(pred):\n    labels_ids = pred.label_ids\n    pred_ids = pred.predictions\n\n    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n    label_str = processor.batch_decode(labels_ids, skip_special_tokens=True)\n\n    cer = cer_metric.compute(predictions=pred_str, references=label_str)\n    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n\n    # Простейшая посимвольная точность\n    total_chars = sum(len(label) for label in label_str)\n    correct_chars = sum(p == l for p_seq, l_seq in zip(pred_str, label_str)\n                        for p, l in zip(p_seq, l_seq))\n    acc = correct_chars / total_chars if total_chars > 0 else 0.0\n\n    return {\n        \"cer\": cer,\n        \"wer\": wer,\n        \"char_accuracy\": acc,\n    }\n\nfrom transformers import default_data_collator\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    tokenizer=processor,  # можно оставить, warning не критичен\n    data_collator=default_data_collator,\n    compute_metrics=compute_metrics  # если используешь\n)\n\ntrainer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nlog_history = trainer.state.log_history\n\n# Собираем все значения\ntrain_loss = [log[\"loss\"] for log in log_history if \"loss\" in log]\neval_loss = [log[\"eval_loss\"] for log in log_history if \"eval_loss\" in log]\ncer = [log[\"eval_cer\"] for log in log_history if \"eval_cer\" in log]\nwer = [log[\"eval_wer\"] for log in log_history if \"eval_wer\" in log]\nchar_acc = [log[\"eval_char_accuracy\"] for log in log_history if \"eval_char_accuracy\" in log]\n\nepochs = list(range(1, len(eval_loss) + 1))\n\n# Отдельный график для Loss\nplt.figure(figsize=(8, 6))\nplt.plot(epochs, train_loss, label=\"Train Loss\")\nplt.plot(epochs, eval_loss, label=\"Val Loss\")\nplt.title(\"График функции потерь\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss-function\")\nplt.legend()\nplt.grid(True)\nplt.savefig(\"train_val_loss.png\")\n\n# Отдельный график для CER\nplt.figure(figsize=(8, 6))\nplt.plot(epochs, cer, label=\"CER\", color='green')\nplt.title(\"Character Error Rate (CER) Over Epochs\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"CER\")\nplt.grid(True)\nplt.savefig(\"Character Error Rate (CER).png\")\n\n# Отдельный график для WER\nplt.figure(figsize=(8, 6))\nplt.plot(epochs, wer, label=\"WER\", color='orange')\nplt.title(\"Word Error Rate (WER) Over Epochs\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"WER\")\nplt.grid(True)\nplt.savefig(\"Word Error Rate (WER).png\")\n\n# Отдельный график для Char Accuracy\nplt.figure(figsize=(8, 6))\nplt.plot(epochs, char_acc, label=\"Accuracy\", color='blue')\nplt.title(\"Accuracy Over Epochs\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.grid(True)\nplt.savefig(\"Accuracy.png\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}